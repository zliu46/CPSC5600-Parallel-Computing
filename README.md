# CPSC5600-Parallel-Computing

Welcome to Parallel Computing

Harnessing the Power of Concurrency
📖 Overview

In this course, we dive into the world of concurrent and parallel computing from both algorithmic and software engineering perspectives.

The terms parallel computing, distributed computing, and concurrent computing are often used interchangeably, but their nuances and overlaps depend on context. By the end of this course, you’ll be equipped not only to use these terms correctly, but also to understand the architectures, tools, and theories behind them in depth.

    🔄 Parallel computing is no longer reserved for supercomputers in government labs.
    📱 Even everyday laptops come with multi-core processors.
    ☁️ Cloud infrastructure is built on massive distributed systems, all leveraging parallelism.
    🧠 As Moore’s Law slows, performance gains are now driven by clever concurrency—not just hardware.

🎯 Course Outcomes

By the end of the course, you will:

    ✅ Understand the distinctions and overlaps among concurrent, parallel, and distributed computing.

    ✅ Be familiar with major parallel computing models: shared memory, message passing, and distributed file-based coordination.

    ✅ Gain experience with tools and technologies specific to each model.

    ✅ Be able to measure and reason about performance in parallel computing environments.

    ✅ Apply parallel computing theory to design, implement, and evaluate real-world solutions.

    ✅ Design, write, test, and debug parallel programs using various paradigms and frameworks.

🏆 Program Outcomes

This course contributes to the following computer science program objectives:

    Design & Evaluation: Ability to create and assess solutions that meet defined requirements.

    Theory & Practice: Apply theoretical principles to practical computing problems.

    Abstraction & Reasoning: Explain solutions across multiple levels of abstraction.

    Adaptability: Learn and apply new tools and techniques in a fast-changing tech landscape.

    Communication (Graduate students only): Communicate effectively with varied technical and non-technical audiences.

🧠 Topics Covered

    Introduction to concurrency and parallelism

    Threads, processes, and synchronization

    Shared memory models (e.g., OpenMP, pthreads)

    Message-passing interfaces (e.g., MPI)

    Distributed coordination mechanisms

    Performance measurement & scalability

    Debugging and correctness in concurrent programs

⚙️ Hands-On Work

Expect a mix of:

    Lectures and technical readings

    Hands-on coding assignments and projects

    Performance profiling and analysis

    Critical discussions and presentations
